{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom torchvision import transforms, models\nfrom PIL import Image\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.metrics import (\n    accuracy_score,\n    confusion_matrix,\n    classification_report,\n    roc_curve,\n    auc\n)\n\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nBATCH_SIZE = 16\nEPOCHS = 30\nLR = 3e-4\nWEIGHT_DECAY = 1e-4\nPATIENCE = 7\n\nNUM_CLASSES = 2\nATTN_DIM = 1024\n\nDATA_ROOT = \"/kaggle/input/breast-cancer-msi-multimodal-image-dataset/MultiModel Breast Cancer MSI Dataset\"\n\nMODALITIES = [\n    \"Chest_XRay_MSI\",\n    \"Histopathological_MSI\",\n    \"Ultrasound Images_MSI\"\n]\n\nLABEL_MAP = {\n    \"benign\": 0, \"Benign\": 0,\n    \"normal\": 0, \"Normal\": 0,\n    \"malignant\": 1, \"Malignant\": 1\n}\n\n# Dataset Description\n\nclass MSIDataset(Dataset):\n    def __init__(self, root, modalities, transform=None):\n        self.samples = []\n        self.transform = transform\n\n        for mod in modalities:\n            mod_path = os.path.join(root, mod)\n            for cls in os.listdir(mod_path):\n                cls_path = os.path.join(mod_path, cls)\n                if not os.path.isdir(cls_path):\n                    continue\n                label = LABEL_MAP.get(cls, -1)\n                if label == -1:\n                    continue\n                for img in os.listdir(cls_path):\n                    self.samples.append((os.path.join(cls_path, img), label, mod))\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, idx):\n        path, label, modality = self.samples[idx]\n        img = Image.open(path).convert(\"RGB\")\n        if self.transform:\n            img = self.transform(img)\n        return img, label, modality\n\n# CBAM\n\nclass CBAM(nn.Module):\n    def __init__(self, channel, reduction=16):\n        super().__init__()\n        self.mlp = nn.Sequential(\n            nn.Linear(channel, channel // reduction),\n            nn.ReLU(),\n            nn.Linear(channel // reduction, channel)\n        )\n        self.sigmoid = nn.Sigmoid()\n        self.conv = nn.Conv2d(2, 1, kernel_size=7, padding=3)\n\n    def forward(self, x):\n        B, C, _, _ = x.shape\n\n        avg = x.mean((2, 3))\n        mx = torch.amax(x, (2, 3))\n        attn = self.sigmoid(self.mlp(avg) + self.mlp(mx))\n        x = x * attn.view(B, C, 1, 1)\n\n        avg_map = x.mean(1, keepdim=True)\n        max_map, _ = x.max(1, keepdim=True)\n        spatial = self.sigmoid(self.conv(torch.cat([avg_map, max_map], 1)))\n\n        return x * spatial\n\n# Modality Specific Backbone\n\ndef build_backbone(mod):\n    if mod == \"Chest_XRay_MSI\":\n        m = models.densenet121(weights=models.DenseNet121_Weights.IMAGENET1K_V1)\n        return nn.Sequential(\n            m.features,\n            CBAM(1024),\n            nn.ReLU(),\n            nn.AdaptiveAvgPool2d(1)\n        ), 1024\n\n    if mod == \"Histopathological_MSI\":\n        m = models.efficientnet_b3(weights=models.EfficientNet_B3_Weights.IMAGENET1K_V1)\n        return nn.Sequential(\n            m.features,\n            CBAM(1536),\n            nn.AdaptiveAvgPool2d(1)\n        ), 1536\n\n    if mod == \"Ultrasound Images_MSI\":\n        m = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n        return nn.Sequential(\n            *list(m.children())[:-2],\n            CBAM(2048),\n            nn.AdaptiveAvgPool2d(1)\n        ), 2048\n\n# Gated Cross-Attention \n\nclass GatedCrossAttention(nn.Module):\n    def __init__(self, dim):\n        super().__init__()\n        self.attn = nn.MultiheadAttention(dim, num_heads=1, batch_first=True)\n        self.gate = nn.Sequential(nn.Linear(dim, 1), nn.Sigmoid())\n        self.norm = nn.LayerNorm(dim)\n\n    def forward(self, q, ctx):\n        attn_out, _ = self.attn(q, ctx, ctx)\n        gate = self.gate(attn_out)\n        return self.norm(q + gate * attn_out)\n\n# Multimodal Model\n\nclass MultimodalFusionNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.backbones = nn.ModuleDict()\n        self.proj = nn.ModuleDict()\n\n        for mod in MODALITIES:\n            bb, d = build_backbone(mod)\n            self.backbones[mod] = bb\n            self.proj[mod] = nn.Linear(d, ATTN_DIM)\n\n        self.cross_attn = GatedCrossAttention(ATTN_DIM)\n        self.classifier = nn.Sequential(\n            nn.LayerNorm(ATTN_DIM),\n            nn.Linear(ATTN_DIM, NUM_CLASSES)\n        )\n\n    def forward(self, x, mods):\n        B = x.size(0)\n        feats = torch.zeros(B, ATTN_DIM, device=x.device)\n\n        for mod in MODALITIES:\n            idx = [i for i, m in enumerate(mods) if m == mod]\n            if idx:\n                f = self.backbones[mod](x[idx]).flatten(1)\n                f = self.proj[mod](f)\n                feats[idx] = f\n\n        fused = self.cross_attn(feats.unsqueeze(1), feats.unsqueeze(1)).squeeze(1)\n        return self.classifier(fused)\n\n# Training Function\n\ndef train(model, train_dl, val_dl):\n    optimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n\n    train_loss, val_loss = [], []\n    train_acc, val_acc = [], []\n\n    best_val, wait = 0, 0\n\n    for ep in range(EPOCHS):\n        model.train()\n        preds, gts, losses = [], [], []\n\n        for x, y, m in train_dl:\n            x, y = x.to(DEVICE), y.to(DEVICE)\n            optimizer.zero_grad()\n\n            out = model(x, m)\n            loss = criterion(out, y)\n            loss.backward()\n            optimizer.step()\n\n            losses.append(loss.item())\n            preds += out.argmax(1).cpu().tolist()\n            gts += y.cpu().tolist()\n\n        tr_acc = accuracy_score(gts, preds) * 100\n        train_loss.append(np.mean(losses))\n        train_acc.append(tr_acc)\n\n        model.eval()\n        preds, gts, losses = [], [], []\n        with torch.no_grad():\n            for x, y, m in val_dl:\n                out = model(x.to(DEVICE), m)\n                loss = criterion(out, y.to(DEVICE))\n                losses.append(loss.item())\n                preds += out.argmax(1).cpu().tolist()\n                gts += y.tolist()\n\n        va_acc = accuracy_score(gts, preds) * 100\n        val_loss.append(np.mean(losses))\n        val_acc.append(va_acc)\n\n        print(f\"Epoch {ep+1}/{EPOCHS} | Train Acc {tr_acc:.2f}% | Val Acc {va_acc:.2f}%\")\n\n        if va_acc > best_val:\n            best_val = va_acc\n            wait = 0\n            torch.save(model.state_dict(), \"best_model.pth\")\n        else:\n            wait += 1\n            if wait >= PATIENCE:\n                print(f\"\\nEarly stopping | Best Val Acc = {best_val:.2f}%\")\n                break\n\n    return train_loss, val_loss, train_acc, val_acc\n\ndef plot_curves(tl, vl, ta, va):\n    epochs = range(1, len(tl) + 1)\n\n    plt.figure()\n    plt.plot(epochs, tl, label=\"Train Loss\")\n    plt.plot(epochs, vl, label=\"Val Loss\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.title(\"Training & Validation Loss\")\n    plt.legend()\n    plt.show()\n\n    plt.figure()\n    plt.plot(epochs, ta, label=\"Train Accuracy\")\n    plt.plot(epochs, va, label=\"Val Accuracy\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Accuracy (%)\")\n    plt.title(\"Training & Validation Accuracy\")\n    plt.legend()\n    plt.show()\n\n# Evaluation Function\n\ndef evaluate(model, val_dl):\n    model.eval()\n    preds, labels, probs = [], [], []\n\n    with torch.no_grad():\n        for x, y, m in val_dl:\n            out = model(x.to(DEVICE), m)\n            p = torch.softmax(out, dim=1)[:, 1]\n            preds += out.argmax(1).cpu().tolist()\n            labels += y.tolist()\n            probs += p.cpu().tolist()\n\n    cm = confusion_matrix(labels, preds)\n    sns.heatmap(cm, annot=True, fmt=\"d\",\n                xticklabels=[\"Benign/Normal\", \"Malignant\"],\n                yticklabels=[\"Benign/Normal\", \"Malignant\"])\n    plt.title(\"Confusion Matrix\")\n    plt.show()\n\n    print(classification_report(labels, preds))\n\n    fpr, tpr, _ = roc_curve(labels, probs)\n    roc_auc = auc(fpr, tpr)\n\n    plt.figure()\n    plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.4f}\")\n    plt.plot([0,1],[0,1],'--')\n    plt.xlabel(\"FPR\")\n    plt.ylabel(\"TPR\")\n    plt.title(\"ROC Curve\")\n    plt.legend()\n    plt.show()\n\n# Main Function\n\ndef main():\n    transform = transforms.Compose([\n        transforms.Resize((224,224)),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize(\n            mean=[0.485,0.456,0.406],\n            std=[0.229,0.224,0.225]\n        )\n    ])\n\n    dataset = MSIDataset(DATA_ROOT, MODALITIES, transform)\n    t = int(0.8 * len(dataset))\n    v = len(dataset) - t\n    train_ds, val_ds = random_split(dataset, [t, v])\n\n    collate = lambda b: (\n        torch.stack([x[0] for x in b]),\n        torch.tensor([x[1] for x in b]),\n        [x[2] for x in b]\n    )\n\n    train_dl = DataLoader(train_ds, BATCH_SIZE, True, collate_fn=collate)\n    val_dl = DataLoader(val_ds, BATCH_SIZE, False, collate_fn=collate)\n\n    model = MultimodalFusionNet().to(DEVICE)\n    tl, vl, ta, va = train(model, train_dl, val_dl)\n\n    plot_curves(tl, vl, ta, va)\n\n    model.load_state_dict(torch.load(\"best_model.pth\"))\n    evaluate(model, val_dl)\n\nif __name__ == \"__main__\":\n    main()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}