{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom torchvision import transforms, models\nfrom PIL import Image\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.metrics import (\n    accuracy_score,\n    confusion_matrix,\n    roc_curve,\n    auc,\n    classification_report\n)\n\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nBATCH_SIZE = 8\nEPOCHS = 30\nLR = 1e-4\nPATIENCE = 5\n\nBASE_DIR = \"/kaggle/input/breast-cancer-msi-multimodal-image-dataset/MultiModel Breast Cancer MSI Dataset\"\n\nMODALITIES = [\n    \"Chest_XRay_MSI\",\n    \"Histopathological_MSI\",\n    \"Ultrasound Images_MSI\"\n]\n\nLABEL_MAP = {\n    \"benign\": 0, \"Benign\": 0,\n    \"normal\": 0, \"Normal\": 0,\n    \"malignant\": 1, \"Malignant\": 1\n}\n\nclass MSI_Dataset(Dataset):\n    def __init__(self, base_dir, modalities, transform=None):\n        self.samples = []\n        self.transform = transform\n\n        for mod in modalities:\n            mod_path = os.path.join(base_dir, mod)\n            if not os.path.isdir(mod_path):\n                print(f\"WARNING: missing folder {mod_path}\")\n                continue\n\n            for cls in os.listdir(mod_path):\n                cls_path = os.path.join(mod_path, cls)\n                if not os.path.isdir(cls_path):\n                    continue\n\n                label = LABEL_MAP.get(cls, None)\n                if label is None:\n                    continue\n\n                for fname in os.listdir(cls_path):\n                    fpath = os.path.join(cls_path, fname)\n                    if os.path.isfile(fpath):\n                        self.samples.append((fpath, label, mod))\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, idx):\n        path, label, modality = self.samples[idx]\n        img = Image.open(path).convert(\"RGB\")\n        if self.transform:\n            img = self.transform(img)\n        return img, label, modality\n\n# ResNet-50 as Backbone\n\ndef get_resnet50_backbone():\n    model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n    return nn.Sequential(*list(model.children())[:-1])  # (B,2048,1,1)\n\n# Multimodal Model\n\nclass MultiModalResNet50(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.enc_chest = get_resnet50_backbone()\n        self.enc_hist  = get_resnet50_backbone()\n        self.enc_ultra = get_resnet50_backbone()\n\n        self.classifier = nn.Sequential(\n            nn.Linear(2048 * 3, 1024),\n            nn.ReLU(),\n            nn.Dropout(0.5),\n            nn.Linear(1024, 512),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(512, 2)\n        )\n\n    def forward(self, imgs, modalities):\n        B = imgs.size(0)\n        device = imgs.device\n\n        chest_idx = [i for i,m in enumerate(modalities) if m == \"Chest_XRay_MSI\"]\n        hist_idx  = [i for i,m in enumerate(modalities) if m == \"Histopathological_MSI\"]\n        ultra_idx = [i for i,m in enumerate(modalities) if m == \"Ultrasound Images_MSI\"]\n\n        feats = [\n            torch.zeros((B,2048), device=device),\n            torch.zeros((B,2048), device=device),\n            torch.zeros((B,2048), device=device)\n        ]\n\n        if chest_idx:\n            f = self.enc_chest(imgs[chest_idx]).view(len(chest_idx), -1)\n            for j,k in enumerate(chest_idx): feats[0][k] = f[j]\n\n        if hist_idx:\n            f = self.enc_hist(imgs[hist_idx]).view(len(hist_idx), -1)\n            for j,k in enumerate(hist_idx): feats[1][k] = f[j]\n\n        if ultra_idx:\n            f = self.enc_ultra(imgs[ultra_idx]).view(len(ultra_idx), -1)\n            for j,k in enumerate(ultra_idx): feats[2][k] = f[j]\n\n        fused = torch.cat(feats, dim=1)\n        return self.classifier(fused)\n\n\n# Image Transformation\n\ntransform = transforms.Compose([\n    transforms.Resize((224,224)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(15),\n    transforms.ToTensor(),\n    transforms.Normalize(\n        mean=[0.485,0.456,0.406],\n        std=[0.229,0.224,0.225]\n    )\n])\n\n# Training Function\n\ndef train_model(model, train_loader, val_loader):\n    model.to(DEVICE)\n    optimizer = optim.Adam(model.parameters(), lr=LR)\n    criterion = nn.CrossEntropyLoss()\n\n    best_val = 0\n    wait = 0\n\n    for ep in range(EPOCHS):\n        model.train()\n        preds, gts = [], []\n\n        for imgs, labels, mods in train_loader:\n            imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n            out = model(imgs, mods)\n            loss = criterion(out, labels)\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            preds += out.argmax(1).cpu().tolist()\n            gts += labels.cpu().tolist()\n\n        train_acc = accuracy_score(gts, preds)\n\n        model.eval()\n        preds, gts = [], []\n        with torch.no_grad():\n            for imgs, labels, mods in val_loader:\n                out = model(imgs.to(DEVICE), mods)\n                preds += out.argmax(1).cpu().tolist()\n                gts += labels.tolist()\n\n        val_acc = accuracy_score(gts, preds)\n        print(f\"Epoch {ep+1}/{EPOCHS} | TrainAcc={train_acc:.4f} | ValAcc={val_acc:.4f}\")\n\n        if val_acc > best_val:\n            best_val = val_acc\n            wait = 0\n            torch.save(model.state_dict(), \"best_model_resnet50.pth\")\n        else:\n            wait += 1\n            if wait >= PATIENCE:\n                print(\"Early stopping triggered\")\n                break\n\n    return best_val\n\n# Evaluation\n\ndef evaluate(model, loader):\n    model.eval()\n    preds, labels, probs = [], [], []\n\n    with torch.no_grad():\n        for imgs, y, mods in loader:\n            out = model(imgs.to(DEVICE), mods)\n            p = torch.softmax(out, dim=1)[:, 1]\n\n            preds += out.argmax(1).cpu().tolist()\n            labels += y.tolist()\n            probs += p.cpu().tolist()\n\n    cm = confusion_matrix(labels, preds)\n    sns.heatmap(cm, annot=True, fmt=\"d\",\n                xticklabels=[\"Benign/Normal\", \"Malignant\"],\n                yticklabels=[\"Benign/Normal\", \"Malignant\"])\n    plt.title(\"Confusion Matrix\")\n    plt.xlabel(\"Predicted\")\n    plt.ylabel(\"Actual\")\n    plt.show()\n\n    print(classification_report(labels, preds,\n          target_names=[\"Benign/Normal\", \"Malignant\"]))\n\n    fpr, tpr, _ = roc_curve(labels, probs)\n    roc_auc = auc(fpr, tpr)\n\n    plt.figure()\n    plt.plot(fpr, tpr, label=f\"ROC Curve (AUC = {roc_auc:.4f})\")\n    plt.plot([0,1],[0,1],'--')\n    plt.xlabel(\"False Positive Rate\")\n    plt.ylabel(\"True Positive Rate\")\n    plt.title(\"ROCâ€“AUC Curve\")\n    plt.legend()\n    plt.show()\n\n# Main Function \n\ndataset = MSI_Dataset(BASE_DIR, MODALITIES, transform)\ntrain_size = int(0.8 * len(dataset))\nval_size = len(dataset) - train_size\ntrain_ds, val_ds = random_split(dataset, [train_size, val_size])\n\ntrain_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\nval_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n\nmodel = MultiModalResNet50()\nbest_acc = train_model(model, train_loader, val_loader)\n\nprint(\"\\nTraining Completed | Best Validation Accuracy:\", best_acc)\n\nmodel.load_state_dict(torch.load(\"best_model_resnet50.pth\"))\nevaluate(model, val_loader)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}